{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "sentence1 = \"I love machine learning\"\n",
        "sentence2 = \"I enjoy studying machine learning\"\n",
        "sentences = [sentence1, sentence2]\n"
      ],
      "metadata": {
        "id": "tQBp_xB-u6Vv"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **BASIC VECTORIZATION TECHNIQUES (frequency Based)**"
      ],
      "metadata": {
        "id": "vDscgiXIwX9w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1️ One-Hot Encoding (OHE)**"
      ],
      "metadata": {
        "id": "Q0_Sivv4u9Oe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "vectorizer = CountVectorizer(binary=True)\n",
        "vectors = vectorizer.fit_transform(sentences)\n",
        "\n",
        "print(\"Vocabulary:\", vectorizer.get_feature_names_out())\n",
        "print(\"OHE vectors:\\n\", vectors.toarray())\n",
        "\n",
        "similarity = cosine_similarity(vectors[0], vectors[1])\n",
        "print(\"OHE Similarity:\", similarity[0][0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qn7vI_s8u6Ss",
        "outputId": "f3b10a83-6afd-44f8-a512-9f28f53e16f4"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary: ['enjoy' 'learning' 'love' 'machine' 'studying']\n",
            "OHE vectors:\n",
            " [[0 1 1 1 0]\n",
            " [1 1 0 1 1]]\n",
            "OHE Similarity: 0.5773502691896258\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2 Bag of Words (BoW)**"
      ],
      "metadata": {
        "id": "dMnw42d1vNdr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer()\n",
        "vectors = vectorizer.fit_transform(sentences)\n",
        "\n",
        "print(\"BoW vectors:\\n\", vectors.toarray())\n",
        "\n",
        "similarity = cosine_similarity(vectors[0], vectors[1])\n",
        "print(\"BoW Similarity:\", similarity[0][0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DycmYyXu6P9",
        "outputId": "38092586-3a8b-4333-9ab0-4c76ecf615fa"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BoW vectors:\n",
            " [[0 1 1 1 0]\n",
            " [1 1 0 1 1]]\n",
            "BoW Similarity: 0.5773502691896258\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3 N-grams (Bi-grams)**"
      ],
      "metadata": {
        "id": "t1sdtzrMvU0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer(ngram_range=(2,2))\n",
        "vectors = vectorizer.fit_transform(sentences)\n",
        "\n",
        "print(\"Bi-gram vocabulary:\", vectorizer.get_feature_names_out())\n",
        "print(\"Bi-gram vectors:\\n\", vectors.toarray())\n",
        "\n",
        "similarity = cosine_similarity(vectors[0], vectors[1])\n",
        "print(\"N-gram Similarity:\", similarity[0][0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vUlgRrKu6Jc",
        "outputId": "bfbd1144-c4d2-4b30-816d-e45a2030779a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bi-gram vocabulary: ['enjoy studying' 'love machine' 'machine learning' 'studying machine']\n",
            "Bi-gram vectors:\n",
            " [[0 1 1 0]\n",
            " [1 0 1 1]]\n",
            "N-gram Similarity: 0.408248290463863\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4️ TF-IDF**"
      ],
      "metadata": {
        "id": "-RE1rcWZvibT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectors = vectorizer.fit_transform(sentences)\n",
        "\n",
        "print(\"TF-IDF vectors:\\n\", vectors.toarray())\n",
        "\n",
        "similarity = cosine_similarity(vectors[0], vectors[1])\n",
        "print(\"TF-IDF Similarity:\", similarity[0][0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4lLJIBEu6G5",
        "outputId": "adc70add-8a42-41eb-fedc-ac32724a27e4"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF vectors:\n",
            " [[0.         0.50154891 0.70490949 0.50154891 0.        ]\n",
            " [0.57615236 0.40993715 0.         0.40993715 0.57615236]]\n",
            "TF-IDF Similarity: 0.4112070550676187\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tIl74yulu6CX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **VECTOR EMBEDDDING TECHNIQUES (Semantic meaning Based)**"
      ],
      "metadata": {
        "id": "21JOGsw2weiB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1 Word2Vec**"
      ],
      "metadata": {
        "id": "6bSd4hR0voLS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "\n",
        "model = api.load(\"word2vec-google-news-300\")\n",
        "\n",
        "def sentence_vector(sentence):\n",
        "    words = sentence.lower().split()\n",
        "    vectors = [model[word] for word in words if word in model]\n",
        "    return np.mean(vectors, axis=0)\n",
        "\n",
        "vec1 = sentence_vector(sentence1)\n",
        "vec2 = sentence_vector(sentence2)\n",
        "\n",
        "similarity = cosine_similarity([vec1], [vec2])\n",
        "print(\"Word2Vec Similarity:\", similarity[0][0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFROyGsTu59Z",
        "outputId": "6da5a805-fa74-4c4e-eea0-b674240a4368"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n",
            "Word2Vec Similarity: 0.83297575\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f385r1FKu57A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2 LLM-Based (Sentence Transformer)**"
      ],
      "metadata": {
        "id": "0q9NiZwbv8MP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "embeddings = model.encode(sentences)\n",
        "\n",
        "similarity = util.cos_sim(embeddings[0], embeddings[1])\n",
        "print(\"LLM-Based Similarity:\", similarity.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DqGRrhlu54m",
        "outputId": "953eaf74-17c0-4460-99e1-db6569be20fa"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM-Based Similarity: 0.7824221849441528\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x7Ih3_qpu52N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "feJgSpJvu5zW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "\n",
        "sentence1 = \"The customer service was excellent and very helpful.\"\n",
        "sentence2 = \"The support team was great and solved my issue quickly\"\n",
        "\n",
        "\n",
        "# transformer model\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# embeddings\n",
        "embeddings = model.encode([sentence1, sentence2])\n",
        "\n",
        "# cosine similarity\n",
        "cosine_score = util.cos_sim(embeddings[0], embeddings[1])\n",
        "\n",
        "\n",
        "print(f\"Sentence 1: {sentence1}\")\n",
        "print(f\"Sentence 2: {sentence2}\")\n",
        "\n",
        "\n",
        "print(f\"Embeding shape {embeddings.shape}\")\n",
        "print(embeddings[0][:5])\n",
        "print(embeddings[1][:5])\n",
        "\n",
        "\n",
        "print(f\"Similarity Score: {cosine_score.item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdgpoTc_cqmd",
        "outputId": "68f9e8a8-3ccc-4ed2-d4d2-0d1cda30c494"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence 1: The customer service was excellent and very helpful.\n",
            "Sentence 2: The support team was great and solved my issue quickly\n",
            "Embeding shape (2, 384)\n",
            "[-0.10404737  0.02839851  0.02214675 -0.03633233 -0.08666304]\n",
            "[-0.06493975 -0.02756827  0.00640762 -0.02886446  0.04612743]\n",
            "Similarity Score: 0.3724\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BL6kSTs-wK4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c6vsciNmwK1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **FAQ Question Matching System**"
      ],
      "metadata": {
        "id": "E8Eiyj2FwKZ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "faqs = [\n",
        "    {\n",
        "        \"question\": \"How can I reset my password?\",\n",
        "        \"answer\": \"Go to settings and click on 'Reset Password'.\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"How do I change my email address?\",\n",
        "        \"answer\": \"You can change your email from profile settings.\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"What is the refund policy?\",\n",
        "        \"answer\": \"Refunds are processed within 5–7 working days.\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"How to contact customer support?\",\n",
        "        \"answer\": \"You can contact support via email or chat.\"\n",
        "    }\n",
        "]\n"
      ],
      "metadata": {
        "id": "6ob8yPNbdzDW"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "faq_questions = [faq[\"question\"] for faq in faqs]\n",
        "\n",
        "faq_embeddings = model.encode(faq_questions)\n"
      ],
      "metadata": {
        "id": "T1BZNJ6HsWka"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "user_query = \"I forgot my password and cannot login\"\n",
        "\n",
        "query_embedding = model.encode(user_query)\n",
        "\n",
        "similarities = util.cos_sim(query_embedding, faq_embeddings)\n",
        "\n",
        "\n",
        "best_score = -1\n",
        "best_faq = None\n",
        "\n",
        "for i in range(len(faqs)):\n",
        "    score = similarities[0][i].item()\n",
        "\n",
        "    if score > best_score:\n",
        "        best_score = score\n",
        "        best_faq = faqs[i]\n",
        "\n",
        "\n",
        "print(\"User Question:\", user_query)\n",
        "print(\"Matched FAQ:\", best_faq[\"question\"])\n",
        "print(\"Answer:\", best_faq[\"answer\"])\n",
        "print(\"Similarity Score:\", round(best_score, 4))\n",
        "\n",
        "\n",
        "def similarity_label(score):\n",
        "    if score > 0.8:\n",
        "        return \"Highly Relevant\"\n",
        "    elif score > 0.6:\n",
        "        return \"Relevant\"\n",
        "    elif score > 0.4:\n",
        "        return \"Weak Match\"\n",
        "    else:\n",
        "        return \"No Good Match\"\n",
        "\n",
        "print(\"Match Type:\", similarity_label(best_score))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4q6rH2CdzBN",
        "outputId": "13a43dc6-b441-4629-8cad-e6e6553b1bbb"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User Question: I forgot my password and cannot login\n",
            "Matched FAQ: How can I reset my password?\n",
            "Answer: Go to settings and click on 'Reset Password'.\n",
            "Similarity Score: 0.8119\n",
            "Match Type: Highly Relevant\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VUMNt6l_dy8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FdPy1VG2dy50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KpiyiQjody3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JUce8vD2dy1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Coq-G4FSdyys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sentence-transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KI4SBYfcWmFM",
        "outputId": "91a897eb-7ce8-404c-e6dd-770791a136fd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
            "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.9.0+cpu)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.36.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.11.12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S31m7QpsWpBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CKw9r5q2akES"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}